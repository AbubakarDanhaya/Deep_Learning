{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cac9a76",
   "metadata": {},
   "source": [
    "# INTRODUCTION TO DEEP LEARNING WITH PYTORCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc990ea",
   "metadata": {},
   "source": [
    ">In this notebook, I am going to practice all what i have learnt for deep learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9298f3be",
   "metadata": {},
   "source": [
    "#### `TENSOR`\n",
    "\n",
    " * Similar to array or matrix\n",
    " * Building block of neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b6b624f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the tensor: torch.Size([2, 3])\n",
      "dtype of the tensor: torch.int64\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "\n",
    "my_list = [[1, 2, 3], [4, 5, 6]]\n",
    "tensor = torch.tensor(my_list)\n",
    "\n",
    "print(\"shape of the tensor:\", tensor.shape)\n",
    "print(\"dtype of the tensor:\", tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf71f5a",
   "metadata": {},
   "source": [
    "#### `Single Linear Layer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b55dd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4361, -0.5689]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.tensor([[0.3471, 0.4547, -0.2356]])\n",
    "\n",
    "linear_layer = nn.Linear(in_features = 3,\n",
    "                         out_features= 2)\n",
    "output = linear_layer(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d6c631",
   "metadata": {},
   "source": [
    "### `Addition of tensors`\n",
    "\n",
    "tensors can be added if the have same dimesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d857acb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[72, 75, 78],\n",
      "        [70, 73, 76]])\n"
     ]
    }
   ],
   "source": [
    "temperature = [[72, 75, 78], [70, 73, 76]]\n",
    "\n",
    "# Create a tensor from temperature\n",
    "temp_tensor = torch.tensor(temperature)\n",
    "print(temp_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78f85491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[74, 77, 80],\n",
      "        [72, 75, 78]])\n"
     ]
    }
   ],
   "source": [
    "adjustment = torch.tensor([[2, 2, 2], [2, 2, 2]])\n",
    "adjust_temp = temp_tensor + adjustment\n",
    "\n",
    "print(adjust_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "441f4819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.8131]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.Tensor([[2, 3, 6, 7, 9, 3, 2, 1]])\n",
    "\n",
    "# Create a container for stacking linear layers\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 4),\n",
    "    nn.Linear(4, 1)\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79ff6e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2374,  1.3487]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.Tensor([[2, 7, 9, 5, 3]])\n",
    "\n",
    "#Create neural network with three hidden layers\n",
    "model = nn.Sequential(nn.Linear(5, 10),\n",
    "                      nn.Linear(10, 15),\n",
    "                      nn.Linear(15, 2))\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0814d6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 41\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(8, 4),\n",
    "                      nn.Linear(4, 1))\n",
    "\n",
    "# Calculate the number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fb90da",
   "metadata": {},
   "source": [
    "### `Multiplication of matrix`\n",
    "\n",
    "* A * B is called elements wise multiplications\n",
    "* A @ B is called matrix multiplications\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c5a9592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[144, 150, 156],\n",
      "        [140, 146, 152]])\n"
     ]
    }
   ],
   "source": [
    "print(temp_tensor * adjustment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51006b45",
   "metadata": {},
   "source": [
    "### `Sigmoid Activation`\n",
    "The sigmoid function is essential for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a478a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9975])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.tensor([6.0])\n",
    "\n",
    "# Apply sigmoid activation function\n",
    "sigmoid = nn.Sigmoid()\n",
    "output = sigmoid(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2f0354",
   "metadata": {},
   "source": [
    "This value indicates a high likelihood of the input belonging to the positive class\n",
    "\n",
    "### `Softmax`\n",
    "The softmax activation function is use for multi-class classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77a6dce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0420, 0.1142, 0.8438])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.tensor([2.0, 3.0, 5.0])\n",
    "\n",
    "# Applying sofmax activation function\n",
    "softmax = nn.Softmax(dim=-1)\n",
    "output = softmax(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc620a1",
   "metadata": {},
   "source": [
    "### `Neural Networks and Activation Functions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "816f1105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4445]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model= nn.Sequential(nn.Linear(3, 1),\n",
    "                     nn.Sigmoid())\n",
    "\n",
    "input_tensor = torch.tensor([[1.0, 0.0, 1.0]])\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e291419d",
   "metadata": {},
   "source": [
    "### `Running a Forward Pass`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1073905b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4633],\n",
      "        [0.5607],\n",
      "        [0.6028],\n",
      "        [0.7641],\n",
      "        [0.4234]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(6, 4)\n",
    "        self.layer2 = nn.Linear(4, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "# Example input data: 5 animals with 6 features each\n",
    "input_data = torch.randn(5, 6)\n",
    "model = SimpleNet()\n",
    "output = model(input_data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3686fc61",
   "metadata": {},
   "source": [
    "The output is a tensor of probabilities for each animal being mammal. Probabilities above 0.5 are classified as `mammals`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cd10a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7156,  1.0850,  0.9732, -0.6339, -0.1748,  0.6600],\n",
      "        [ 0.8810, -0.8619, -0.7653, -0.4784, -0.9159, -0.2109],\n",
      "        [ 0.0279,  0.8680, -0.1871, -0.8715,  0.1015, -0.8748],\n",
      "        [ 0.6029, -0.8699, -0.7344,  0.9807,  1.6170,  0.0275],\n",
      "        [ 0.1348,  0.5761,  0.5089,  0.1204, -0.9634, -0.3321]])\n"
     ]
    }
   ],
   "source": [
    "print(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2341dfd",
   "metadata": {},
   "source": [
    "### `Multi-Class Classification with Softmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60b0331c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4966, 0.1265, 0.3769],\n",
      "        [0.5191, 0.2973, 0.1836],\n",
      "        [0.5221, 0.1684, 0.3095],\n",
      "        [0.5169, 0.2256, 0.2575],\n",
      "        [0.5609, 0.2224, 0.2167]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiClassNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiClassNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(6, 4)\n",
    "        self.layer2 = nn.Linear(4, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = F.softmax(x, dim = -1)\n",
    "        return x\n",
    "    \n",
    "input_data = torch.randn(5, 6)\n",
    "model = MultiClassNet()\n",
    "output = model(input_data)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2af9334",
   "metadata": {},
   "source": [
    "Each row in the output represents probabilities for the three classes, summing to one. the class with the highest probability is the predicted label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2eb01e",
   "metadata": {},
   "source": [
    "### `Understanding One-Hot Encoding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5c7b552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot vector using Numpy: [0 1 0]\n",
      "One-hot vector using PyTorch: tensor([0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y=1\n",
    "num_classes = 3\n",
    "\n",
    "# Create the one-hot encoded vector using Numpy\n",
    "one_hot_numpy = np.array([0, 1, 0])\n",
    "\n",
    "# Create the one-hot encoded vector using PyTorch\n",
    "one_hot_pytorch = F.one_hot(torch.tensor(y), num_classes= num_classes)\n",
    "\n",
    "print(\"One-hot vector using Numpy:\", one_hot_numpy)\n",
    "print(\"One-hot vector using PyTorch:\", one_hot_pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6906b76a",
   "metadata": {},
   "source": [
    "### `Calculating Cross-Entropy Loss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad3db8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-entropy loss: 1.4170299768447876\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "#Ground truth label\n",
    "y= torch.tensor([1])\n",
    "\n",
    "# Scores (Predictions before softmax)\n",
    "scores = torch.tensor([[2.0, 1.0, 0.1]])\n",
    "\n",
    "# Define the cross-entropy loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# Compute the Loss\n",
    "loss = criterion(scores, y)\n",
    "\n",
    "print(\"Cross-entropy loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9975e52",
   "metadata": {},
   "source": [
    "### `Using Loss Functions to Assess Model Predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8da6e954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Loss: 0.1914976636771114\n"
     ]
    }
   ],
   "source": [
    "y = torch.tensor([0])\n",
    "scores = torch.tensor([[2.5, 0.3, 0.2]])\n",
    "one_hot_target = F.one_hot(y, num_classes=3)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "loss = criterion(scores.double(), y)\n",
    "\n",
    "print(\"Computed Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168f1457",
   "metadata": {},
   "source": [
    "### `Understanding Gradients in Neural Networks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37fe319b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of the first layer's weight is: tensor([[ 0.1482,  0.0043, -0.1023, -0.0039, -0.1097,  0.0224,  0.0454,  0.2888,\n",
      "          0.1159,  0.0032,  0.0332,  0.1866,  0.1981,  0.0955, -0.0572, -0.0839],\n",
      "        [ 0.2364,  0.0069, -0.1632, -0.0062, -0.1750,  0.0357,  0.0725,  0.4607,\n",
      "          0.1848,  0.0051,  0.0530,  0.2976,  0.3160,  0.1524, -0.0912, -0.1338],\n",
      "        [ 0.0718,  0.0021, -0.0496, -0.0019, -0.0531,  0.0108,  0.0220,  0.1399,\n",
      "          0.0561,  0.0015,  0.0161,  0.0904,  0.0960,  0.0463, -0.0277, -0.0406],\n",
      "        [-0.0584, -0.0017,  0.0403,  0.0015,  0.0432, -0.0088, -0.0179, -0.1138,\n",
      "         -0.0456, -0.0013, -0.0131, -0.0735, -0.0780, -0.0376,  0.0225,  0.0330],\n",
      "        [-0.2308, -0.0067,  0.1594,  0.0061,  0.1709, -0.0348, -0.0708, -0.4498,\n",
      "         -0.1804, -0.0050, -0.0517, -0.2906, -0.3086, -0.1488,  0.0891,  0.1306],\n",
      "        [ 0.0330,  0.0010, -0.0228, -0.0009, -0.0244,  0.0050,  0.0101,  0.0644,\n",
      "          0.0258,  0.0007,  0.0074,  0.0416,  0.0441,  0.0213, -0.0127, -0.0187],\n",
      "        [-0.3488, -0.0102,  0.2409,  0.0092,  0.2583, -0.0526, -0.1070, -0.6797,\n",
      "         -0.2727, -0.0075, -0.0781, -0.4392, -0.4663, -0.2249,  0.1346,  0.1974],\n",
      "        [-0.3212, -0.0094,  0.2218,  0.0085,  0.2378, -0.0484, -0.0985, -0.6259,\n",
      "         -0.2511, -0.0069, -0.0720, -0.4044, -0.4294, -0.2071,  0.1239,  0.1818]])\n",
      "Gradient of the first layer's bias is: tensor([ 0.1572, -0.7131,  0.2497,  0.3062])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(nn.Linear(16, 8),\n",
    "                      nn.Linear(8, 4))\n",
    "\n",
    "input_data = torch.randn(1, 16)\n",
    "output = model(input_data)\n",
    "\n",
    "#Define a loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "target = torch.tensor([1])\n",
    "loss = criterion(output, target)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "# Backward pass to calculate gradients\n",
    "gradient_layer_0 = model[0].weight.grad\n",
    "bia_gradient_layer_0 = model[1].bias.grad\n",
    "\n",
    "print(\"Gradient of the first layer's weight is:\", gradient_layer_0)\n",
    "print(\"Gradient of the first layer's bias is:\", bia_gradient_layer_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47418e6",
   "metadata": {},
   "source": [
    "### `Updates Weight and Bias with PyTorch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c290db66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight before optimizer step: Parameter containing:\n",
      "tensor([[-0.0113, -0.0550, -0.2444,  0.1280,  0.0853,  0.0687,  0.1321,  0.0325,\n",
      "         -0.2291,  0.2177, -0.1854,  0.1484,  0.2020,  0.1689,  0.1137,  0.0463],\n",
      "        [ 0.1752,  0.2480, -0.1871,  0.0224,  0.2012, -0.2292,  0.0633,  0.0943,\n",
      "          0.1150, -0.2078, -0.0101, -0.1592,  0.0765, -0.2244, -0.1416, -0.2406],\n",
      "        [-0.2426, -0.0853, -0.1868, -0.1256,  0.2195, -0.0058,  0.1958, -0.1753,\n",
      "          0.1177, -0.1173,  0.2420,  0.0097, -0.0499,  0.0353,  0.2160, -0.1433],\n",
      "        [-0.0701, -0.0824, -0.0226,  0.1291,  0.1527, -0.1853,  0.1433,  0.2086,\n",
      "         -0.1257,  0.1260, -0.1213,  0.1199, -0.0201, -0.0542, -0.1638, -0.2018],\n",
      "        [ 0.0535, -0.2344, -0.1646,  0.0906, -0.2000, -0.1331, -0.1247,  0.2406,\n",
      "         -0.1065, -0.1759,  0.2273,  0.1124,  0.1106,  0.1590, -0.2441, -0.0374],\n",
      "        [ 0.2149,  0.0352,  0.0307,  0.0742,  0.0173,  0.1108, -0.2255,  0.1076,\n",
      "          0.0543,  0.1882,  0.2127, -0.0640,  0.2478,  0.0929,  0.0940,  0.0034],\n",
      "        [ 0.0840, -0.1739, -0.2128,  0.2360, -0.2027,  0.1128, -0.1131, -0.1985,\n",
      "         -0.0587, -0.1715, -0.0104, -0.1988, -0.1089, -0.1863, -0.0400, -0.0376],\n",
      "        [ 0.0256,  0.0004, -0.0269, -0.1563, -0.1046, -0.1697,  0.1174, -0.1918,\n",
      "          0.1742,  0.2435, -0.0346,  0.0143,  0.2083, -0.0384, -0.1157, -0.2298]],\n",
      "       requires_grad=True)\n",
      "Weigts after otimizer step: Parameter containing:\n",
      "tensor([[-0.0143, -0.0551, -0.2423,  0.1280,  0.0875,  0.0682,  0.1312,  0.0267,\n",
      "         -0.2314,  0.2177, -0.1861,  0.1447,  0.1980,  0.1670,  0.1149,  0.0480],\n",
      "        [ 0.1705,  0.2479, -0.1838,  0.0226,  0.2047, -0.2300,  0.0618,  0.0851,\n",
      "          0.1113, -0.2079, -0.0112, -0.1652,  0.0702, -0.2275, -0.1398, -0.2379],\n",
      "        [-0.2441, -0.0853, -0.1858, -0.1256,  0.2205, -0.0061,  0.1954, -0.1781,\n",
      "          0.1166, -0.1173,  0.2417,  0.0079, -0.0518,  0.0343,  0.2165, -0.1424],\n",
      "        [-0.0690, -0.0823, -0.0234,  0.1291,  0.1518, -0.1852,  0.1437,  0.2109,\n",
      "         -0.1247,  0.1261, -0.1211,  0.1214, -0.0185, -0.0535, -0.1642, -0.2024],\n",
      "        [ 0.0581, -0.2343, -0.1677,  0.0905, -0.2034, -0.1324, -0.1233,  0.2496,\n",
      "         -0.1029, -0.1758,  0.2283,  0.1182,  0.1168,  0.1620, -0.2459, -0.0400],\n",
      "        [ 0.2142,  0.0352,  0.0312,  0.0742,  0.0178,  0.1107, -0.2257,  0.1063,\n",
      "          0.0538,  0.1882,  0.2126, -0.0648,  0.2470,  0.0925,  0.0943,  0.0038],\n",
      "        [ 0.0910, -0.1737, -0.2176,  0.2358, -0.2078,  0.1138, -0.1109, -0.1849,\n",
      "         -0.0533, -0.1713, -0.0089, -0.1900, -0.0995, -0.1818, -0.0427, -0.0416],\n",
      "        [ 0.0320,  0.0006, -0.0313, -0.1564, -0.1094, -0.1687,  0.1194, -0.1793,\n",
      "          0.1792,  0.2436, -0.0331,  0.0224,  0.2169, -0.0342, -0.1182, -0.2334]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#Define optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
    "\n",
    "#forward pass and calculate loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "output = model(input_data)\n",
    "loss = criterion(output, target)\n",
    "\n",
    "#Backward pass to calculate gradients\n",
    "loss.backward()\n",
    "print(\"Weight before optimizer step:\", model[0].weight)\n",
    "\n",
    "#Update weights using the optimizer\n",
    "optimizer.step()\n",
    "\n",
    "#Print update weight\n",
    "print(\"Weigts after otimizer step:\", model[0].weight) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161ff4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
